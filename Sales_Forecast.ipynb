{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bda5700",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ“Š Sales Forecasting Project\n",
    "\n",
    "Hey! This is my attempt at building a simple sales forecasting model.  \n",
    "The idea is to take sales data (daily/weekly), do some feature engineering, and then train a model (LightGBM) to predict future sales.\n",
    "\n",
    "I'll go step by step so itâ€™s easy to follow.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630f16cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "# just to keep results consistent\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacdad55",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Load the data\n",
    "\n",
    "I have a CSV file with sales data. I'll load it here.  \n",
    "(Change the filename if your dataset has a different name.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f087254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "DATA_PATH = \"/mnt/data/submission.csv\"  # change if needed\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"Shape of data:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a029e279",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Quick look at the data\n",
    "\n",
    "Letâ€™s check missing values, datatypes, and a quick plot of sales over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef76195",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df.info())\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "df.describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e81dec4",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Preprocessing\n",
    "\n",
    "Now Iâ€™ll make sure the date column is in datetime format,  \n",
    "and then set the target variable (sales).\n",
    "\n",
    "ðŸ‘‰ Change `DATE_COL` and `TARGET` below if your dataset uses different column names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9e515",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Change these if needed\n",
    "DATE_COL = \"date\"    # example: 'date', 'order_date', etc.\n",
    "TARGET = \"sales\"     # example: 'sales', 'y', etc.\n",
    "\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL])\n",
    "df = df.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "# If multiple rows per day, aggregate\n",
    "daily = df.groupby(DATE_COL)[TARGET].sum().reset_index()\n",
    "daily.rename(columns={TARGET: \"y\"}, inplace=True)\n",
    "daily.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaff53bc",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Feature engineering\n",
    "\n",
    "Iâ€™ll add some date-based features (day, month, weekday, etc.)  \n",
    "and also create lag/rolling features (previous sales, moving averages).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5a79ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = daily.copy()\n",
    "data['day'] = data[DATE_COL].dt.day\n",
    "data['month'] = data[DATE_COL].dt.month\n",
    "data['year'] = data[DATE_COL].dt.year\n",
    "data['dayofweek'] = data[DATE_COL].dt.dayofweek\n",
    "\n",
    "# Lags and rolling averages\n",
    "for lag in [1, 7, 14]:\n",
    "    data[f\"lag_{lag}\"] = data[\"y\"].shift(lag)\n",
    "\n",
    "for window in [7, 14]:\n",
    "    data[f\"roll_mean_{window}\"] = data[\"y\"].shift(1).rolling(window).mean()\n",
    "\n",
    "# drop rows with NaN (from lagging)\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce95f62",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Train-test split\n",
    "\n",
    "Iâ€™ll keep the last 30 days for testing and train on the rest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831d9149",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TEST_DAYS = 30\n",
    "train = data.iloc[:-TEST_DAYS]\n",
    "test = data.iloc[-TEST_DAYS:]\n",
    "\n",
    "FEATURES = [c for c in data.columns if c not in [DATE_COL, \"y\"]]\n",
    "print(\"Features:\", FEATURES)\n",
    "\n",
    "X_train, y_train = train[FEATURES], train[\"y\"]\n",
    "X_test, y_test = test[FEATURES], test[\"y\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe202e8",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Train a model\n",
    "\n",
    "Iâ€™ll use a LightGBM regressor (works well for tabular + time series features).  \n",
    "Also scaling features with StandardScaler inside a pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2a5eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lgb\", lgb.LGBMRegressor(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"RMSE:\", rmse(y_test, y_pred))\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MAPE:\", mape(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca60847",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Predictions vs Actual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900dcb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(test[DATE_COL], y_test, marker=\"o\", label=\"Actual\")\n",
    "plt.plot(test[DATE_COL], y_pred, marker=\"o\", label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.title(\"Sales Forecast (Last 30 days)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d594783b",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Save model\n",
    "\n",
    "Finally, Iâ€™ll save the trained model so we can reuse it later (deployment, API, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bccc22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "joblib.dump(model, \"/mnt/data/sales_forecast_model.joblib\")\n",
    "print(\"Model saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25982ed2",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Save predictions in a clean format for Power BI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6138d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = test.copy()\n",
    "results[\"Predicted_Sales\"] = y_pred\n",
    "results = results[[\"date\", \"sales\", \"Predicted_Sales\"]]\n",
    "\n",
    "results.to_csv(\"sales_forecast_results.csv\", index=False)\n",
    "print(\"Saved: sales_forecast_results.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
